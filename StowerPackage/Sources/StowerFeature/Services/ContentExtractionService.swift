import Foundation
import SwiftSoup

// Remove @MainActor to allow CPU-heavy parsing off main thread  
public final class ContentExtractionService: Sendable {
    public let debugLogger: (@Sendable (String) -> Void)?
    
    public init(debugLogger: (@Sendable (String) -> Void)? = nil) {
        self.debugLogger = debugLogger
    }
    
    private func log(_ message: String) {
        print(message)
        debugLogger?(message)
    }
    
    public func extractContent(from html: String, baseURL: URL?) async throws -> ExtractedContent {
        // Check if this is actually PDF content (sometimes URLs redirect to PDFs)
        if let baseURL = baseURL, isPDFURL(baseURL.absoluteString) {
            self.log("üìÑ Detected PDF URL, using PDF extraction service")
            let pdfService = PDFExtractionService(debugLogger: debugLogger)
            return try await pdfService.extractContent(from: baseURL)
        }
        
        // Move CPU-heavy parsing off main thread using Task.detached
        return try await Task.detached {
            // TODO: Re-enable Foundation Models once beta issues are resolved
            // Temporarily disable Foundation Models due to crashes in iOS 26 beta
            self.log("ü§ñ Foundation Models temporarily disabled due to beta instability, using traditional extraction")
            
            // Try traditional SwiftSoup-based extraction first
            let traditionalResult = try self.extractContentTraditional(from: html, baseURL: baseURL)
            
            self.log("üîç Traditional extraction result: \(traditionalResult.markdown.count) characters")
            
            // If traditional extraction yields very little content (likely JavaScript-rendered site),
            // fall back to WebView-based extraction
            if traditionalResult.markdown.count < 100 && baseURL != nil {
                self.log("‚ö†Ô∏è Traditional extraction yielded only \(traditionalResult.markdown.count) characters, trying WebView extraction")
                // Switch to main actor for WebView operations
                return try await Task { @MainActor in
                    try await self.extractContentWithWebView(url: baseURL!)
                }.value
            }
            
            self.log("‚úÖ Using traditional extraction result (\(traditionalResult.markdown.count) characters)")
            return traditionalResult
        }.value
    }
    
    public func extractContent(from data: Data, mimeType: String?, baseURL: URL?) async throws -> ExtractedContent {
        // Check if this is PDF data
        if let mimeType = mimeType, mimeType == "application/pdf" {
            self.log("üìÑ Detected PDF data, using PDF extraction service")
            let pdfService = PDFExtractionService(debugLogger: debugLogger)
            return try await pdfService.extractContent(from: data)
        }
        
        // Check PDF magic bytes as fallback
        if data.count >= 4 {
            let pdfHeader = data.prefix(4)
            if pdfHeader == Data([0x25, 0x50, 0x44, 0x46]) { // "%PDF"
                self.log("üìÑ Detected PDF by magic bytes, using PDF extraction service")
                let pdfService = PDFExtractionService(debugLogger: debugLogger)
                return try await pdfService.extractContent(from: data)
            }
        }
        
        // Convert data to string and process as HTML
        guard let htmlString = String(data: data, encoding: .utf8) else {
            throw NSError(domain: "ContentExtractionError", code: 1, userInfo: [NSLocalizedDescriptionKey: "Could not convert data to string"])
        }
        
        return try await extractContent(from: htmlString, baseURL: baseURL)
    }
    
    private func isPDFURL(_ urlString: String) -> Bool {
        return urlString.lowercased().hasSuffix(".pdf")
    }
    
    @MainActor
    private func extractContentWithWebView(url: URL) async throws -> ExtractedContent {
        log("üåê Starting WebView-based content extraction for: \(url.absoluteString)")
        
        let extractor = WebViewContentExtractor()
        extractor.debugLogger = debugLogger
        let renderedHTML = try await extractor.extractRenderedHTML(from: url)
        
        log("‚úÖ WebView extraction completed, processing \(renderedHTML.count) characters of rendered HTML")
        
        // Now use traditional extraction on the fully-rendered HTML
        return try extractContentTraditional(from: renderedHTML, baseURL: url)
    }
    
    
    private func extractContentTraditional(from html: String, baseURL: URL?) throws -> ExtractedContent {
        log("üîç ContentExtractionService: Starting extraction for URL: \(baseURL?.absoluteString ?? "unknown")")
        log("üìÑ HTML length: \(html.count) characters")
        
        let document = try SwiftSoup.parse(html)
        
        // Debug: Check body content
        let bodyText: String
        if let body = document.body() {
            bodyText = try body.text()
            log("üîç Body element text length: \(bodyText.count) characters")
            log("üîç Body children count: \(body.children().count)")
            if bodyText.count > 100 {
                log("üîç First 200 chars of body: '\(String(bodyText.prefix(200)))'")
            }
        } else {
            log("‚ùå No body element found!")
            bodyText = ""
        }
        
        // Extract title
        let title = try extractTitle(from: document, fallbackURL: baseURL)
        log("üìù Extracted title: '\(title)'")
        
        // Clean HTML by removing noise
        let cleanedDocument = try cleanHTML(document)
        
        // Debug: Check what cleaning did to the content
        if let cleanedBody = cleanedDocument.body() {
            let cleanedBodyText = try cleanedBody.text()
            log("üîç After cleaning: body has \(cleanedBodyText.count) characters")
            log("üîç Cleaning threshold: \(bodyText.count / 10) characters")
            if cleanedBodyText.count < bodyText.count / 10 || (bodyText.count > 1000 && cleanedBodyText.count < 100) {
                log("‚ö†Ô∏è Cleaning removed significant content! (\(bodyText.count) -> \(cleanedBodyText.count))")
                log("üîß Using original document instead of cleaned version")
                // Find main content using original document if cleaning was too aggressive
                let mainContent = try findMainContent(in: document)
                log("üéØ Main content tag: \(mainContent.tagName())")
                let mainContentText = try mainContent.text()
                log("üìä Main content text length: \(mainContentText.count) characters")
                log("üîç Main content preview: '\(String(mainContentText.prefix(200)))'")
                
                // Convert to markdown
                let markdown = try convertToMarkdown(mainContent, baseURL: baseURL)
                log("‚úÖ Markdown length: \(markdown.count) characters")
                log("üìñ First 200 chars of markdown: '\(String(markdown.prefix(200)))'")
                
                // Extract images
                let images = try extractImages(from: mainContent, baseURL: baseURL)
                log("üñºÔ∏è Found \(images.count) images")
                
                return ExtractedContent(
                    title: title,
                    markdown: markdown,
                    images: images,
                    rawHTML: try document.html()
                )
            }
        } else {
            log("‚ùå No body element found after cleaning!")
            log("üîß Cleaning completely removed body element, using original document")
            // Find main content using original document if cleaning removed the body
            let mainContent = try findMainContent(in: document)
            log("üéØ Main content tag: \(mainContent.tagName())")
            let mainContentText = try mainContent.text()
            log("üìä Main content text length: \(mainContentText.count) characters")
            log("üîç Main content preview: '\(String(mainContentText.prefix(200)))'")
            
            // Convert to markdown
            let markdown = try convertToMarkdown(mainContent, baseURL: baseURL)
            log("‚úÖ Markdown length: \(markdown.count) characters")
            log("üìñ First 200 chars of markdown: '\(String(markdown.prefix(200)))'")
            
            // Extract images
            let images = try extractImages(from: mainContent, baseURL: baseURL)
            log("üñºÔ∏è Found \(images.count) images")
            
            return ExtractedContent(
                title: title,
                markdown: markdown,
                images: images,
                rawHTML: try document.html()
            )
        }
        
        // Find main content using text density algorithm
        let mainContent = try findMainContent(in: cleanedDocument)
        log("üéØ Main content tag: \(mainContent.tagName())")
        let mainContentText = try mainContent.text()
        log("üìä Main content text length: \(mainContentText.count) characters")
        log("üîç Main content preview: '\(String(mainContentText.prefix(200)))'")
        
        // Convert to markdown
        let markdown = try convertToMarkdown(mainContent, baseURL: baseURL)
        log("‚úÖ Markdown length: \(markdown.count) characters")
        log("üìñ First 200 chars of markdown: '\(String(markdown.prefix(200)))'")
        
        // Extract images
        let images = try extractImages(from: mainContent, baseURL: baseURL)
        log("üñºÔ∏è Found \(images.count) images")
        
        return ExtractedContent(
            title: title,
            markdown: markdown,
            images: images,
            rawHTML: try document.html()
        )
    }
    
    // MARK: - Title Extraction
    
    private func extractTitle(from document: Document, fallbackURL: URL?) throws -> String {
        // Try title tag first
        if let titleElement = try document.select("title").first() {
            let title = try titleElement.text().trimmingCharacters(in: .whitespacesAndNewlines)
            if !title.isEmpty {
                return title
            }
        }
        
        // Try Open Graph title
        if let ogTitle = try document.select("meta[property=og:title]").first() {
            let title = try ogTitle.attr("content").trimmingCharacters(in: .whitespacesAndNewlines)
            if !title.isEmpty {
                return title
            }
        }
        
        // Try first h1
        if let h1 = try document.select("h1").first() {
            let title = try h1.text().trimmingCharacters(in: .whitespacesAndNewlines)
            if !title.isEmpty {
                return title
            }
        }
        
        // Fallback to URL host
        return fallbackURL?.host() ?? "Untitled Article"
    }
    
    // MARK: - HTML Cleaning
    
    private func cleanHTML(_ document: Document) throws -> Document {
        // Create a copy to avoid modifying the original
        let cleanedDocument = try SwiftSoup.parse(try document.html())
        
        // Remove unwanted elements
        let unwantedSelectors = [
            "script", "style", "nav", "header", "footer", "aside",
            ".ad", ".ads", ".advertisement", ".sponsored", ".popup",
            ".sidebar", ".social", ".comments", ".related",
            "[role=banner]", "[role=navigation]", "[role=complementary]"
        ]
        
        for selector in unwantedSelectors {
            try cleanedDocument.select(selector).remove()
        }
        
        // Remove elements with suspicious class/id names
        let suspiciousPatterns = [
            "[class*=ad]", "[id*=ad]", "[class*=sponsor]", "[id*=sponsor]",
            "[class*=popup]", "[id*=popup]", "[class*=overlay]", "[id*=overlay]"
        ]
        
        for pattern in suspiciousPatterns {
            try cleanedDocument.select(pattern).remove()
        }
        
        return cleanedDocument
    }
    
    // MARK: - Main Content Detection
    
    private func findMainContent(in document: Document) throws -> Element {
        log("üéØ Starting main content detection...")
        
        // First, try semantic HTML5 elements
        let semanticSelectors = ["article", "main", "[role=main]", ".content", ".post", ".entry"]
        
        for selector in semanticSelectors {
            if let element = try document.select(selector).first() {
                let textLength = try element.text().count
                if textLength > 100 { // Minimum content threshold
                    log("‚úÖ Found semantic content: \(selector) with \(textLength) characters")
                    return element
                }
                log("‚è≠Ô∏è Skipping \(selector) - only \(textLength) characters")
            } else {
                log("‚ùå No elements found for selector: \(selector)")
            }
        }
        
        // Try common content patterns
        let contentSelectors = [
            ".post-content", ".article-content", ".entry-content", 
            ".story-body", ".article-body", ".post-body",
            "#content", "#main", "#post",
            // Ghost blog specific selectors
            ".gh-content", ".post-full-content", ".kg-card-markdown"
        ]
        
        for selector in contentSelectors {
            if let element = try document.select(selector).first() {
                let textLength = try element.text().count
                if textLength > 100 {
                    log("‚úÖ Found content pattern: \(selector) with \(textLength) characters")
                    return element
                }
                log("‚è≠Ô∏è Skipping \(selector) - only \(textLength) characters")
            } else {
                log("‚ùå No elements found for selector: \(selector)")
            }
        }
        
        // If no semantic elements, use improved text density algorithm
        log("üîç Falling back to text density algorithm...")
        return try findContentByTextDensity(in: document)
    }
    
    private func findContentByTextDensity(in document: Document) throws -> Element {
        let bodyElement = document.body() ?? document
        
        // Debug: Check if body itself should be a candidate
        let bodyText = try bodyElement.text()
        log("üîç Body element has \(bodyText.count) characters")
        
        // Debug: Check what document we're working with
        if bodyText.count < 100 {
            log("‚ö†Ô∏è Body element unexpectedly small in text density algorithm!")
            log("üîç Body children in density algorithm: \(bodyElement.children().count)")
            if bodyElement.children().count > 0 {
                let firstChild = bodyElement.children().first()!
                log("üîç First child tag: \(firstChild.tagName())")
                log("üîç First child text: \(try firstChild.text().count) characters")
            }
        }
        
        // More comprehensive candidate selection - try broader selector first
        var candidates = try bodyElement.select("div, section, article, p, main, span, aside")
        
        // Add body element as a candidate if it has substantial content
        if bodyText.count > 100 {
            log("üîç Adding body element as candidate")
            var mutableCandidates = Array(candidates)
            mutableCandidates.insert(bodyElement, at: 0)
            candidates = Elements(mutableCandidates)
        }
        
        // If we get no candidates, get ALL elements
        if candidates.isEmpty {
            log("‚ö†Ô∏è No standard candidates found, expanding to all elements...")
            candidates = try bodyElement.select("*")
        }
        
        // If still no candidates, use direct children
        if candidates.isEmpty {
            log("‚ö†Ô∏è No elements found, using body children...")
            candidates = bodyElement.children()
        }
        
        var bestCandidate: Element?
        var bestScore = 0.0
        
        log("üîç Evaluating \(candidates.count) content candidates...")
        
        // Debug: Show all candidates with any text content
        var candidatesWithText = 0
        var largeCandidates = 0
        for candidate in candidates {
            let textLength = try candidate.text().count
            if textLength > 0 {
                candidatesWithText += 1
                if textLength > 1000 {
                    largeCandidates += 1
                    let candidateClass = try candidate.attr("class").lowercased()
                    let candidateId = try candidate.attr("id").lowercased()
                    let tagName = candidate.tagName().lowercased()
                    log("üîç LARGE candidate \(largeCandidates): \(tagName) class='\(candidateClass)' id='\(candidateId)' - \(textLength) chars")
                }
                if candidatesWithText <= 5 { // Show first 5 candidates with text
                    let candidateClass = try candidate.attr("class").lowercased()
                    let candidateId = try candidate.attr("id").lowercased()
                    let tagName = candidate.tagName().lowercased()
                    log("üîç Debug candidate \(candidatesWithText): \(tagName) class='\(candidateClass)' id='\(candidateId)' - \(textLength) chars")
                }
            }
        }
        log("üîç Found \(candidatesWithText) candidates with text content, \(largeCandidates) with >1000 chars")
        
        for candidate in candidates {
            // Get attributes for filtering
            let candidateClass = try candidate.attr("class").lowercased()
            let candidateId = try candidate.attr("id").lowercased()
            let tagName = candidate.tagName().lowercased()
            
            // Skip navigation, sidebars, ads, and other non-content elements
            let skipPatterns = ["nav", "sidebar", "menu", "header", "footer", "ad", "widget", 
                               "social", "share", "comment", "related", "popup", "modal", 
                               "banner", "promo", "newsletter"]
            
            let shouldSkip = skipPatterns.contains { pattern in
                candidateClass.contains(pattern) || candidateId.contains(pattern)
            }
            
            if shouldSkip {
                print("‚è≠Ô∏è Skipping non-content element: \(tagName) class='\(candidateClass)' id='\(candidateId)'")
                continue
            }
            
            // Skip very large containers that are likely page wrappers
            if candidateClass.contains("root") || candidateId.contains("root") ||
               candidateClass.contains("app") || candidateId.contains("app") ||
               candidateClass.contains("page") || candidateId.contains("page") ||
               candidateClass.contains("container") || candidateId.contains("container") {
                
                // But allow if they contain "content" 
                if !candidateClass.contains("content") && !candidateId.contains("content") {
                    print("‚è≠Ô∏è Skipping large container: \(tagName) class='\(candidateClass)' id='\(candidateId)'")
                    continue
                }
            }
            
            let textLength = try candidate.text().count
            
            // Skip elements that are too short, but be more lenient
            if textLength < 20 {
                print("‚è≠Ô∏è Skipping due to short length: \(tagName) - \(textLength) chars")
                continue
            }
            
            // Skip extremely long elements (but allow up to 100k for long articles)
            if textLength > 100000 {
                print("‚è≠Ô∏è Skipping due to excessive length: \(tagName) - \(textLength) chars")
                continue
            }
            
            let score = try calculateTextDensity(for: candidate)
            
            // Only log candidates with substantial text or high scores to reduce noise
            if textLength > 100 || score > 1.0 {
                log("üìä Candidate: \(tagName) class='\(candidateClass)' id='\(candidateId)' - Score: \(String(format: "%.2f", score)), Text: \(textLength) chars")
            }
            
            if score > bestScore && textLength > 50 { // Minimum 50 characters for content
                bestScore = score
                bestCandidate = candidate
                log("üèÜ New best candidate with score \(String(format: "%.2f", score)) and \(textLength) chars")
            }
        }
        
        if let best = bestCandidate {
            print("‚úÖ Selected: \(best.tagName()) with score \(String(format: "%.2f", bestScore))")
            return best
        } else {
            print("‚ùå No good candidate found, using body element")
            
            // Debug: Log body content to understand what we have
            let bodyText = try bodyElement.text()
            print("üîç DEBUG: Body element text length: \(bodyText.count)")
            print("üîç DEBUG: Body element children count: \(bodyElement.children().count)")
            print("üîç DEBUG: First 500 chars of body text: '\(String(bodyText.prefix(500)))'")
            
            // Try to find any div with substantial content as fallback
            let fallbackCandidates = try bodyElement.select("div")
            print("üîç DEBUG: Found \(fallbackCandidates.count) div elements")
            
            for (index, candidate) in fallbackCandidates.enumerated() {
                let textLength = try candidate.text().count
                print("üîç DEBUG: Div \(index): \(textLength) characters")
                if index < 3 && textLength > 0 { // Log first 3 non-empty divs
                    let candidateText = try candidate.text()
                    print("üîç DEBUG: Div \(index) text: '\(String(candidateText.prefix(200)))'")
                }
                
                if textLength > 100 { // Reduced from 500 to 100
                    print("üÜò Using fallback div with \(textLength) characters")
                    return candidate
                }
            }
            return bodyElement
        }
    }
    
    private func calculateTextDensity(for element: Element) throws -> Double {
        let text = try element.text()
        let textLength = Double(text.count)
        
        // Count child elements (tags)
        let childElements = try element.select("*").count
        let childElementCount = Double(max(childElements, 1))
        
        // Calculate text density (text length / number of tags)
        let density = textLength / childElementCount
        
        // Bonus for longer text
        let lengthBonus = min(textLength / 1000.0, 1.0)
        
        // Penalty for too many links (likely navigation)
        let links = try element.select("a").count
        let linkPenalty = Double(links) / max(textLength / 100.0, 1.0)
        
        return density + lengthBonus - linkPenalty
    }
    
    // MARK: - Markdown Conversion
    
    private func convertToMarkdown(_ element: Element, baseURL: URL? = nil) throws -> String {
        var markdown = ""
        
        // Process child nodes
        for child in element.children() {
            let childMarkdown = try processElement(child, baseURL: baseURL, depth: 0)
            if !childMarkdown.isEmpty {
                let trimmed = childMarkdown.trimmingCharacters(in: .whitespacesAndNewlines)
                if !trimmed.isEmpty {
                    markdown += trimmed + "\n\n"
                }
            }
        }
        
        // Clean up excessive whitespace and empty lines
        let cleanedMarkdown = markdown
            .replacingOccurrences(of: "\n\n\n+", with: "\n\n", options: .regularExpression)
            .trimmingCharacters(in: .whitespacesAndNewlines)
        
        return cleanedMarkdown
    }
    
    private func processElement(_ element: Element, baseURL: URL? = nil, depth: Int = 0) throws -> String {
        // Prevent infinite recursion
        guard depth < 50 else {
            print("‚ö†Ô∏è Max recursion depth reached for element: \(element.tagName())")
            return ""
        }
        let tagName = element.tagName().lowercased()
        let text = element.ownText()
        
        switch tagName {
        case "h1":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "# " + content
        case "h2":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "## " + content
        case "h3":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "### " + content
        case "h4":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "#### " + content
        case "h5":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "##### " + content
        case "h6":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1).trimmingCharacters(in: .whitespacesAndNewlines)
            return content.isEmpty ? "" : "###### " + content
        case "p":
            return try processInlineElements(element, baseURL: baseURL, depth: depth + 1)
        case "strong", "b":
            return "**" + text + "**"
        case "em", "i":
            return "*" + text + "*"
        case "a":
            let href = try element.attr("href")
            let linkText = try element.text()
            return "[\(linkText)](\(href))"
        case "img":
            // Preserve image as markdown with resolved absolute URL
            let src = (try? element.attr("src")) ?? ""
            let alt = (try? element.attr("alt")) ?? ""
            
            // Only include images with valid src attributes
            if !src.isEmpty {
                // Resolve relative URLs to absolute URLs
                if let resolvedURL = resolveURL(src, baseURL: baseURL) {
                    return "![\(alt)](\(resolvedURL.absoluteString))"
                } else {
                    return "![\(alt)](\(src))"
                }
            }
            return ""
        case "ul", "ol":
            return try processList(element, ordered: tagName == "ol", baseURL: baseURL, depth: depth + 1)
        case "li":
            return try processInlineElements(element, baseURL: baseURL, depth: depth + 1)
        case "blockquote":
            let content = try processInlineElements(element, baseURL: baseURL, depth: depth + 1)
            return "> " + content.replacingOccurrences(of: "\n", with: "\n> ")
        case "code":
            return "`" + text + "`"
        case "pre":
            let codeContent = try element.text().trimmingCharacters(in: .whitespacesAndNewlines)
            return codeContent.isEmpty ? "" : "```\n" + codeContent + "\n```"
        case "br":
            return "\n"
        case "hr":
            return "\n---\n"
        case "div", "section", "article", "header", "footer", "main":
            // Process container elements recursively with proper spacing
            if element.children().count > 0 {
                var result = ""
                for child in element.children() {
                    let childMarkdown = try processElement(child, baseURL: baseURL, depth: depth + 1)
                    if !childMarkdown.isEmpty {
                        let trimmed = childMarkdown.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !trimmed.isEmpty {
                            result += trimmed + "\n\n"
                        }
                    }
                }
                return result.trimmingCharacters(in: .whitespacesAndNewlines)
            } else {
                return text.trimmingCharacters(in: .whitespacesAndNewlines)
            }
        default:
            // For other elements, process children or return text
            if element.children().count > 0 {
                var result = ""
                for child in element.children() {
                    let childMarkdown = try processElement(child, baseURL: baseURL, depth: depth + 1)
                    if !childMarkdown.isEmpty {
                        result += childMarkdown + " "
                    }
                }
                return result.trimmingCharacters(in: .whitespaces)
            } else {
                return text.trimmingCharacters(in: .whitespacesAndNewlines)
            }
        }
    }
    
    private func processInlineElements(_ element: Element, baseURL: URL? = nil, depth: Int = 0) throws -> String {
        var result = ""
        
        for node in element.getChildNodes() {
            if let textNode = node as? TextNode {
                result += textNode.text()
            } else if let childElement = node as? Element {
                result += try processElement(childElement, baseURL: baseURL, depth: depth + 1)
            }
        }
        
        return result.trimmingCharacters(in: .whitespaces)
    }
    
    private func processList(_ element: Element, ordered: Bool, baseURL: URL? = nil, depth: Int = 0) throws -> String {
        var result = ""
        let items = try element.select("li")
        
        for (index, item) in items.enumerated() {
            let prefix = ordered ? "\(index + 1). " : "- "
            let itemText = try processInlineElements(item, baseURL: baseURL, depth: depth + 1)
            result += prefix + itemText + "\n"
        }
        
        return result
    }
    
    // MARK: - Image Extraction
    
    private func extractImages(from element: Element, baseURL: URL?) throws -> [String] {
        let images = try element.select("img[src]")
        var imageURLs: [String] = []
        
        for img in images {
            let src = try img.attr("src")
            if let resolvedURL = resolveURL(src, baseURL: baseURL) {
                imageURLs.append(resolvedURL.absoluteString)
            }
        }
        
        return imageURLs
    }
    
    private func resolveURL(_ urlString: String, baseURL: URL?) -> URL? {
        // First try to create as absolute URL
        if let url = URL(string: urlString), url.scheme != nil {
            return url // Already absolute URL
        }
        
        // Handle relative URLs
        guard let baseURL = baseURL else {
            print("‚ö†Ô∏è No baseURL provided for relative URL: \(urlString)")
            return nil
        }
        
        // Create URL relative to base and resolve it to absolute
        if let relativeURL = URL(string: urlString, relativeTo: baseURL) {
            // Use absoluteURL to convert relative URL to absolute
            let absoluteURL = relativeURL.absoluteURL
            print("üîó Resolved '\(urlString)' with base '\(baseURL.absoluteString)' ‚Üí '\(absoluteURL.absoluteString)'")
            return absoluteURL
        }
        
        print("‚ùå Failed to resolve URL: '\(urlString)' with base '\(baseURL.absoluteString)'")
        return nil
    }
}

// MARK: - Data Models

public struct ExtractedContent: Sendable {
    public let title: String
    public let markdown: String
    public let images: [String]
    public let rawHTML: String
    
    public init(title: String, markdown: String, images: [String], rawHTML: String) {
        self.title = title
        self.markdown = markdown
        self.images = images
        self.rawHTML = rawHTML
    }
}
